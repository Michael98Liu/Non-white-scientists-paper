{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: \n",
    "\n",
    "Gomez, Charles, 2022, \"Replication Data for: Leading countries in global science increasingly receive more citations than other countries doing similar research.\", https://doi.org/10.7910/DVN/WCOINR, Harvard Dataverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Python_Class_LLDA import LLDA\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import re\n",
    "import bz2\n",
    "from ast import literal_eval\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "DIR = '/scratch/fl1092/followup-editors/race_citation_well/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLLDA_Min_Year = 2001 # 1980\n",
    "NLLDA_Max_Year = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ngrams(x):\n",
    "    \n",
    "    x = re.sub(r'[^\\w\\s]', '', x)\n",
    "    \n",
    "    if x.isdigit()==True:\n",
    "        return ''\n",
    "    x = x.lstrip().rstrip()\n",
    "    if len(x)>1:\n",
    "        if x[-1]=='s':\n",
    "            x = x[:-1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCorpusLabel():\n",
    "    \n",
    "    paperRace = (\n",
    "        pd.read_csv(DIR + 'PaperRace.csv', sep='\\t')\n",
    "        .rename(columns={'Race':'labels','PaperId':'paperid'})\n",
    "    )\n",
    "\n",
    "    paperYear = (\n",
    "        pd.read_csv(DIR + 'PaperYear.csv', sep='\\t')\n",
    "        .rename(columns={'Year':'year','PaperId':'paperid'})\n",
    "    )\n",
    "    \n",
    "    paperField = (\n",
    "        pd.read_csv(DIR + 'PaperField.csv', sep='\\t')\n",
    "        .rename(columns={'PaperId':'paperid'})\n",
    "    )\n",
    "    \n",
    "    corpus = (\n",
    "        pd.read_csv(DIR + 'PaperAbstractProcessed.csv', sep='\\t', converters={'RakeAbstract': literal_eval})\n",
    "        .rename(columns={'RakeAbstract':'Abstract','PaperId':'paperid'})\n",
    "        [[\"paperid\",\"Abstract\"]]\n",
    "    )\n",
    "    \n",
    "    return paperRace, paperYear, paperField, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterDiscipline(disp, paperField, paperRace, corpus, paperYear):\n",
    "    \n",
    "    subset = paperField.query(\"FieldOfStudyId == @disp\")\n",
    "    \n",
    "    paperRace = paperRace[paperRace.paperid.isin(subset.paperid)]\n",
    "    corpus = corpus[corpus.paperid.isin(subset.paperid)]    \n",
    "    paperYear = paperYear[paperYear.paperid.isin(subset.paperid)]\n",
    "    \n",
    "    return paperRace, paperYear, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructLLDA(Yearly_Dict_of_Corpora, Yearly_Dict_of_Labels, beta=0.1, alpha=0.1):\n",
    "    \n",
    "    NLLDA_Min_Year = 2001 #1980 \n",
    "    NLLDA_Max_Year = 2017\n",
    "    Dictionary_of_NLLDA = {}\n",
    "\n",
    "    for year_ in range(NLLDA_Min_Year,NLLDA_Max_Year+1,1):\n",
    "        \n",
    "        if year_ not in set(Yearly_Dict_of_Labels.keys()).union(set(Yearly_Dict_of_Corpora.keys())):\n",
    "            continue\n",
    "\n",
    "        labels_list = [label_.split(\" \") for label_ in Yearly_Dict_of_Labels[year_].values()]\n",
    "        labels_set = list(set(list(itertools.chain.from_iterable(labels_list))))\n",
    "\n",
    "        K = len(labels_set) # Number of labels\n",
    "\n",
    "        NLLDA_Model_ = LLDA(K, alpha, beta)\n",
    "        NLLDA_Model_.set_corpus(labels_set, Yearly_Dict_of_Corpora[year_].values(), labels_list)\n",
    "        \n",
    "        #for ite in range(100):\n",
    "        NLLDA_Model_.inference()\n",
    "        \n",
    "        Dictionary_of_NLLDA[year_] = NLLDA_Model_\n",
    "        \n",
    "    return Dictionary_of_NLLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paperRaceDf, paperYear, paperField, corpusDf = loadCorpusLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperRaceDf.shape, paperYear.shape, paperField.shape, corpusDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperField.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = paperField.FieldOfStudyId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for disp in tqdm(fields):\n",
    "\n",
    "    paperRace, df_year_censored, corpus = filterDiscipline(disp, paperField, paperRaceDf, corpusDf, paperYear)\n",
    "    print(disp, paperRace.shape, df_year_censored.shape, corpus.shape)\n",
    "\n",
    "    corpus = corpus.set_index(\"paperid\").to_dict()[\"Abstract\"]\n",
    "\n",
    "    df_labels = paperRace.groupby('paperid')[\"labels\"].apply(lambda x: \" \".join(x)).reset_index(name=\"Labels\")\n",
    "    labels_dict = pd.Series(df_labels.Labels.values,index=df_labels.paperid).to_dict()\n",
    "\n",
    "    year_dict = pd.Series(df_year_censored.year.values, index=df_year_censored.paperid).to_dict()\n",
    "    list_of_years = list(set(year_dict.values()))\n",
    "\n",
    "    Yearly_Dict_of_Corpora = {years_:{} for years_ in list_of_years}\n",
    "    Yearly_Dict_of_Labels = {years_:{} for years_ in list_of_years}\n",
    "\n",
    "    for paperid_, yearid_ in year_dict.items():\n",
    "\n",
    "        if paperid_ in corpus.keys() and paperid_ in labels_dict.keys():\n",
    "            if corpus[paperid_]!=[] and labels_dict[paperid_]!=\"\":\n",
    "                Yearly_Dict_of_Corpora[yearid_].update({paperid_: corpus[paperid_]})\n",
    "                Yearly_Dict_of_Labels[yearid_].update({paperid_: labels_dict[paperid_]})\n",
    "\n",
    "    Yearly_Dict_of_Corpora = {\n",
    "        years_: {\n",
    "            paperid_: [\n",
    "                clean_ngrams(str(term_)) for term_ in abstract_]\n",
    "            for paperid_, abstract_ in year_corpora.items()\n",
    "        } for years_,year_corpora in Yearly_Dict_of_Corpora.items()\n",
    "    }\n",
    "\n",
    "    Yearly_Dict_of_Corpora = {\n",
    "        years_: {\n",
    "            paperid_: [\n",
    "                term_ for term_ in abstract_ if len(term_)>1]\n",
    "            for paperid_, abstract_ in year_corpora.items()\n",
    "        } for years_,year_corpora in Yearly_Dict_of_Corpora.items()\n",
    "    }\n",
    "    \n",
    "    Yearly_NLLDA_Dict_Filename = DIR + f'llda_inf/{disp}.pbz2'\n",
    "\n",
    "    LLDA_dict = constructLLDA(Yearly_Dict_of_Corpora, Yearly_Dict_of_Labels)\n",
    "    \n",
    "    with bz2.BZ2File(Yearly_NLLDA_Dict_Filename, 'w') as f:\n",
    "        \n",
    "        for year in range(NLLDA_Min_Year,NLLDA_Max_Year+1):\n",
    "            try:\n",
    "                pickle.dump(LLDA_dict[year], f, protocol=2)\n",
    "            except Exception as e:\n",
    "                print('ERROR', disp, year, e)\n",
    "                pickle.dump({}, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
