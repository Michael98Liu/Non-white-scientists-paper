{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9af96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "MAGDIR = '/scratch/fl1092/MAG/2021-12-06/' # directory that contains MAG dataset\n",
    "PROJDIR = '/scratch/fl1092/followup-editors/' # directory that contains the original data pre-anonymized\n",
    "DATADIR = '../data/' # directory that contains the anonymized data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0cacf6",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc035bb",
   "metadata": {},
   "source": [
    "## MAG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85390592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPaperAuthor(aff=False):\n",
    "\n",
    "    columns = ['PaperId', 'AuthorId']\n",
    "    if aff:\n",
    "        columns.append('AffiliationId')\n",
    "        \n",
    "    papAu = (\n",
    "        pd.read_csv(MAGDIR+\"mag/PaperAuthorAffiliations.txt\", sep=\"\\t\",\n",
    "                    names = ['PaperId', 'AuthorId', 'AffiliationId', 'AuthorSequenceNumber',\n",
    "                             'OriginalAuthor', 'OriginalAffiliation'],\n",
    "                    usecols = columns,\n",
    "                    dtype = {'PaperId':int, 'AuthorId':int, 'AffiliationId':float}, memory_map=True)\n",
    "        .drop_duplicates()\n",
    "    )\n",
    "    \n",
    "    return papAu\n",
    "\n",
    "def loadRace(threshold=-1, files=[MAGDIR + 'derived/AuthorEthnicity.csv']):\n",
    "    \n",
    "    race = (\n",
    "        pd.concat([pd.read_csv(file, sep='\\t', usecols=['AuthorId','Race','RaceScore']) for file in files],\n",
    "                 sort=False, ignore_index=True)\n",
    "        .query(f\"RaceScore >= {threshold}\")\n",
    "    )\n",
    "    \n",
    "    return race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06970ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paper_journal = pd.read_csv(MAGDIR+'derived/PaperJournal.csv',sep='\\t')\n",
    "paper_year = pd.read_csv(MAGDIR+'derived/PaperYear.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9878d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "papAu = loadPaperAuthor(aff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb79cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "papAuNoAff = loadPaperAuthor(aff=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f53b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oneChina = lambda iso: 'CN' if iso in ['TW', 'HK', 'MO'] else iso\n",
    "\n",
    "affiliations = (\n",
    "    pd.read_csv(MAGDIR + \"mag/Affiliations.txt\", sep=\"\\t\",\n",
    "                names=['AffiliationId', \"Rank\", \"NormalizedName\", \"DisplayName\", \"GridId\",\n",
    "                       \"OfficialPage\", \"WikiPage\", \"PaperCount\",'PaperFamilyCount',\n",
    "                       \"CitationCount\", \"Iso3166Code\", \"Latitude\", \"Longitude\", 'CreatedDate'],\n",
    "                usecols=['AffiliationId', 'Iso3166Code', 'NormalizedName'])\n",
    "    .rename(columns={'Iso3166Code':'iso'})\n",
    "    .assign(iso = lambda df: df.iso.apply(oneChina))\n",
    ")\n",
    "affiliations = affiliations.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a06cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "affYear = pd.read_csv(MAGDIR + 'derived/AuthorAffiliationYear.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604556e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldname = (\n",
    "    pd.read_csv(MAGDIR + \"advanced/FieldsOfStudy.txt\", sep=\"\\t\", \n",
    "                names = [\"FieldOfStudyId\", \"Rank\", \"NormalizedName\", \"DisplayName\", \n",
    "                         \"MainType\",\"Level\",\"PaperCount\",\"PaperFamilyCount\", \"CitationCount\",\"CreatedDate\"],\n",
    "                usecols=['FieldOfStudyId', 'DisplayName']\n",
    "               )\n",
    "    .rename(columns={'FieldOfStudyId':'Field', 'DisplayName':'FieldName'})\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "paperField = (\n",
    "    pd.read_csv(PROJDIR + 'PaperField.csv', sep='\\t', dtype={'PaperId':int}, usecols=['PaperId','Field'])\n",
    "    .merge(fieldname, on='Field')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e5265",
   "metadata": {},
   "outputs": [],
   "source": [
    "nineteenFields = (\n",
    "    paperField[['FieldName']].drop_duplicates().reset_index(drop=True).reset_index()\n",
    "    .rename(columns={'index':'FID'})\n",
    ")\n",
    "nineteenFields.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c4a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "nineteenFields.to_csv(DATADIR + 'Fields.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3abee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "race = loadRace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a46df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "authorCareer = pd.read_csv(MAGDIR+'derived/AuthorCareer.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca0901b",
   "metadata": {},
   "source": [
    "## Paper/editor data from the six publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ddad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPaperEditor():\n",
    "    \n",
    "    papEditor = (\n",
    "        pd.read_csv(PROJDIR + 'PaperEditors.csv',sep='\\t')\n",
    "        .drop_duplicates(subset=['PaperId'], keep=False)\n",
    "    )\n",
    "    \n",
    "    return papEditor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e2e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPaperAuthor(aff=False):\n",
    "\n",
    "    columns = ['PaperId', 'AuthorId']\n",
    "    if aff:\n",
    "        columns.append('AffiliationId')\n",
    "        \n",
    "    papAu = (\n",
    "        pd.read_csv(MAGDIR+\"mag/PaperAuthorAffiliations.txt\", sep=\"\\t\",\n",
    "                    names = ['PaperId', 'AuthorId', 'AffiliationId', 'AuthorSequenceNumber',\n",
    "                             'OriginalAuthor', 'OriginalAffiliation'],\n",
    "                    usecols = columns,\n",
    "                    dtype = {'PaperId':int, 'AuthorId':int, 'AffiliationId':float}, memory_map=True)\n",
    "        .drop_duplicates()\n",
    "    )\n",
    "    \n",
    "    print(papAu.shape)\n",
    "    \n",
    "    return papAu\n",
    "\n",
    "def loadPaperInfo():\n",
    "    \n",
    "    info = pd.read_csv(PROJDIR + 'PaperInfoGathered.csv', sep='\\t',\n",
    "                   usecols=['PaperId','Publisher','Journal'])\n",
    "    \n",
    "    return info\n",
    "\n",
    "def loadJournals():\n",
    "    \n",
    "    journals = pd.concat(\n",
    "        [pd.read_csv(file,sep='\\t',dtype={'JournalId':float}).assign(Publisher = file.split('/')[3].lower())\n",
    "         .dropna().assign(JournalId = lambda df: df.JournalId.astype(int))\n",
    "         for file in glob.glob('/scratch/fl1092/*/JournalToJournalIdMapping.csv')],\n",
    "        ignore_index=True, sort=False\n",
    "    ).drop_duplicates(subset=['JournalId'], keep=False)\n",
    "    \n",
    "    return journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d935ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPaperRecvAcptTime():\n",
    "    \n",
    "    recv = (\n",
    "        pd.read_csv('/scratch/fl1092/followup-editors/RecvTime.csv', sep='\\t', parse_dates=['RecvDate'])\n",
    "        .assign(Year = lambda df: df.RecvDate.apply(lambda x: x.year))\n",
    "    )\n",
    "\n",
    "    acpt = (\n",
    "        pd.read_csv('/scratch/fl1092/followup-editors/AcptTime.csv', sep='\\t', parse_dates=['AcptDate'])\n",
    "        .assign(Year = lambda df: df.AcptDate.apply(lambda x: x.year))\n",
    "    )\n",
    "    \n",
    "    return recv, acpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba00321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPaperDelay(percentage=True, paperYear=None, normalize=False):\n",
    "    \n",
    "    if normalize is True and percentage is True:\n",
    "        print('both are TURE. Prioritize normalizing instead of percentage.')\n",
    "    \n",
    "    if paperYear is None:\n",
    "        paperYear, _ = loadPaperRecvAcptTime()\n",
    "        paperYear = paperYear.drop('RecvDate', axis=1)\n",
    "    \n",
    "    info = pd.read_csv(PROJDIR + 'PaperInfoGathered.csv', sep='\\t',\n",
    "                   usecols=['PaperId','Publisher','Journal'])\n",
    "    \n",
    "    info = info.merge(paperYear, on='PaperId')\n",
    "\n",
    "    acptDelay = pd.read_csv(PROJDIR + 'AcptDelay.csv', sep='\\t', dtype={'AcptDelay':int})\n",
    "\n",
    "    acptDelay = acptDelay[(acptDelay.AcptDelay > 0) & (acptDelay.AcptDelay <= 730)]\n",
    "\n",
    "    journalAverage = (\n",
    "        info.merge(acptDelay, on='PaperId').groupby(['Journal','Year'])\n",
    "        .AcptDelay.mean().reset_index()\n",
    "        .rename(columns={'AcptDelay':'JAvg'})\n",
    "    )\n",
    "    \n",
    "    if normalize:\n",
    "        journalStd = (\n",
    "            info.merge(acptDelay, on='PaperId').groupby(['Journal','Year'])\n",
    "            .AcptDelay.std().reset_index()\n",
    "            .rename(columns={'AcptDelay':'JStd'})\n",
    "        )\n",
    "\n",
    "    acptDelay = (\n",
    "        acptDelay.merge(info, on='PaperId')\n",
    "        .merge(journalAverage, on=['Journal','Year'])\n",
    "    )\n",
    "    \n",
    "    if normalize:\n",
    "        acptDelay = (\n",
    "            acptDelay\n",
    "            \n",
    "            .merge(journalStd, on=['Journal', 'Year'])\n",
    "            .assign(JRelative = lambda df: (df.AcptDelay - df.JAvg)/df.JStd)\n",
    "        )\n",
    "    \n",
    "    elif percentage:\n",
    "        acptDelay = (\n",
    "            acptDelay\n",
    "            \n",
    "            .assign(JRelative = lambda df: df.AcptDelay - df.JAvg)\n",
    "            .assign(JRelative = lambda df: df.JRelative/df.JAvg)\n",
    "        )\n",
    "    \n",
    "    return acptDelay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504296bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPaperCountry():\n",
    "    \n",
    "    country = (\n",
    "        \n",
    "        pd.read_csv('/scratch/fl1092/followup-editors/PaperCountry.csv',sep='\\t',\n",
    "                   dtype={'Percentage':float})\n",
    "    )\n",
    "    \n",
    "    return country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da7a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = loadPaperInfo()\n",
    "journals = loadJournals()\n",
    "paperEditor = loadPaperEditor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cac050",
   "metadata": {},
   "outputs": [],
   "source": [
    "journalToID = (\n",
    "    pd.concat([info[['Journal']], journals[['Journal']]], ignore_index=True, sort=False)\n",
    "    .drop_duplicates().reset_index(drop=True).reset_index()\n",
    "    .rename(columns={'index':'JID'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319c9a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "publisherToID = (\n",
    "    info[['Publisher']].drop_duplicates().reset_index(drop=True).reset_index()\n",
    "    .rename(columns={'index':'PubID'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16319d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "journalToID.to_csv(PROJDIR + \"AnonymizedJournalId.csv\",sep='\\t',index=False)\n",
    "publisherToID.to_csv(DATADIR + \"PublisherId.csv\",sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cbab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapJournalPublisher(df):\n",
    "    assert('Publisher' in df.columns)\n",
    "    assert('Journal' in df.columns)\n",
    "    \n",
    "    resdf = (\n",
    "        df.merge(publisherToID, on='Publisher')\n",
    "        .merge(journalToID, on='Journal')\n",
    "        .drop(['Publisher','Journal'], axis=1)\n",
    "    )\n",
    "    assert(resdf.shape[0] == df.shape[0])\n",
    "    \n",
    "    return resdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53dc7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paperDelay = loadPaperDelay(percentage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d6ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "papCountry = loadPaperCountry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002f84b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "USpapers = (\n",
    "    pd.read_csv(PROJDIR + 'PaperCountryAll.csv', sep='\\t',\n",
    "                usecols=['PaperId','iso','Percentage'])\n",
    "    .query('iso == \"US\"')\n",
    "    .query('Percentage == 1')\n",
    "    .drop(['Percentage','iso'], axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9617e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paperRace = (\n",
    "    pd.read_csv('/scratch/fl1092/followup-editors/PaperRace.csv', sep='\\t')\n",
    "    .query('Race != \"unknown\"')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paperEditorRace(papers, paperEditor=None, race=None, confidence=-1):\n",
    "    \n",
    "    if paperEditor is None: paperEditor = loadPaperEditor()\n",
    "    if race is None: race = loadRace()\n",
    "        \n",
    "    papEdiRace = (\n",
    "        papers.merge(paperEditor, on='PaperId')\n",
    "        .rename(columns={'EditorId':'AuthorId'})\n",
    "        .merge(race.query(f'RaceScore > {confidence}'), on='AuthorId', how='left')\n",
    "        .fillna({'Race':'unknown'})\n",
    "    )\n",
    "    \n",
    "    return papEdiRace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec35942",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "editorRace = paperEditorRace(paperDelay[['PaperId']].drop_duplicates(), race=race)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66fd2eb",
   "metadata": {},
   "source": [
    "## Auxilary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignRegion(row):\n",
    "    \n",
    "    # create a new region \"NA and Oceania\"\n",
    "    \n",
    "    if row.region == 'Americas':\n",
    "        if row['sub-region'] == 'Northern America':\n",
    "            return 'NA and Oceania'\n",
    "        else:\n",
    "            return row['sub-region']\n",
    "        \n",
    "    elif row.region == 'Oceania': return 'NA and Oceania'\n",
    "    else:\n",
    "        return row.region\n",
    "\n",
    "### map from iso code to country names ###\n",
    "isoToC = (\n",
    "    pd.read_csv(DATADIR + 'worldcities.csv',usecols=['iso2','country'])\n",
    "    .drop_duplicates()\n",
    "    .rename(columns={'iso2':'iso'})\n",
    ")\n",
    "isoToC.loc[isoToC.iso == 'US', 'country'] = 'U.S.A.' # replace country name w/ abbreviation USA\n",
    "isoToC.loc[isoToC.iso == 'AE', 'country'] = 'U.A.E.' # replace country name w/ abbreviation UAE\n",
    "isoToC.loc[isoToC.iso == 'GB', 'country'] = 'U.K.' # replace country name w/ abbreviation UK\n",
    "\n",
    "assert(isoToC.iso.duplicated().any() == False)\n",
    "assert(isoToC.country.duplicated().any() == False)\n",
    "### ###\n",
    "\n",
    "### map from ISO codes to regions \n",
    "continents = (\n",
    "    pd.read_csv(DATADIR + 'continents2.csv',usecols=['iso_3166-2','region','sub-region'])\n",
    "    .rename(columns={'iso_3166-2':'iso'})\n",
    "    .assign(iso=lambda df: df.iso.apply(lambda x: x.replace('ISO 3166-2:','')))\n",
    "    .drop_duplicates()\n",
    "    .dropna()\n",
    "    .assign(region=lambda df: df.apply(assignRegion, axis=1))\n",
    "    .drop('sub-region', axis=1)\n",
    ")\n",
    "print(isoToC.shape, continents.shape)\n",
    "### ###\n",
    "\n",
    "### color of countries ###\n",
    "colorsDf = pd.DataFrame({\n",
    "    'region': ['Africa', 'Latin America and the Caribbean', 'Asia', 'Europe', 'NA and Oceania'], \n",
    "    'Color': ['#f34d4d', '#f34d4d', '#f34d4d', '#69bade', '#69bade']}) # white and non-white colors\n",
    "\n",
    "colors = dict(zip(colorsDf.region, colorsDf.Color))\n",
    "###\n",
    "# (223, 2) (248, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99c8c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have verified with the MAG affiliations file that all the names of institution names correspond\n",
    "rank = (\n",
    "    pd.read_csv(DATADIR + 'normaffil_topuniversities_ranking_2019.csv',sep=',',\n",
    "                usecols=['AffID','rank'], dtype={'AffID':int,'rank':str})\n",
    "    .rename(columns={'AffID':'AffiliationId'})\n",
    ")\n",
    "rank = rank.assign(rank=rank['rank'].apply(lambda x: x.split('-')[0]))\n",
    "rank = rank.assign(rank=rank['rank'].astype(int))\n",
    "rank = rank.rename(columns={'rank':'Rank'})\n",
    "rank.shape, rank['Rank'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc43225",
   "metadata": {},
   "source": [
    "# Country representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2812e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# authors of papers in our dataset\n",
    "authors = (\n",
    "    info\n",
    "    .merge(paper_year, on='PaperId')\n",
    "    .merge(papAu, on='PaperId')\n",
    "    .merge(affiliations, on='AffiliationId')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    authors\n",
    "    .pipe(mapJournalPublisher)\n",
    "    .to_csv(\n",
    "        DATADIR + 'country_rep/Authors.tsv', sep='\\t', index=False,\n",
    "        columns=['JID','PubID','iso']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789351ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "editors = (\n",
    "    journals.merge(paper_journal, on='JournalId')\n",
    "    .drop('JournalId', axis=1)\n",
    "    .merge(paper_year, on='PaperId')\n",
    "    \n",
    "    .merge(paperEditor, on='PaperId')\n",
    "    .rename(columns={'EditorId': 'AuthorId'})\n",
    "    .merge(affYear, on=['AuthorId', 'Year'])\n",
    "    .merge(affiliations, on='AffiliationId')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    editors\n",
    "    .pipe(mapJournalPublisher)\n",
    "    .to_csv(\n",
    "        DATADIR + 'country_rep/Editors.tsv', sep='\\t', index=False,\n",
    "        columns=['JID','PubID','iso']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5fb08a",
   "metadata": {},
   "source": [
    "## Country representation by field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce914235",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "editorField = editors.merge(paperField, on='PaperId')\n",
    "authorField = authors.merge(paperField, on='PaperId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6164afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    editorField\n",
    "    .merge(nineteenFields, on='FieldName')\n",
    "    .to_csv(\n",
    "        DATADIR + 'country_rep/EditorsField.tsv', sep='\\t', index=False,\n",
    "        columns=['FID','iso']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1255459",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    authorField\n",
    "    .merge(nineteenFields, on='FieldName')\n",
    "    .to_csv(\n",
    "        DATADIR + 'country_rep/AuthorsField.tsv', sep='\\t', index=False,\n",
    "        columns=['FID','iso']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1520b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "authorFieldTwoPart = (\n",
    "    authorField.reset_index().rename(columns={'index':'AnoID'})\n",
    "    .merge(nineteenFields, on='FieldName')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    authorFieldTwoPart.head(5251439).to_csv(\n",
    "        DATADIR + 'country_rep/AuthorsField_0.tsv', sep='\\t', index=False,\n",
    "        columns=['FID','iso']\n",
    "    )\n",
    ")\n",
    "\n",
    "(\n",
    "    authorFieldTwoPart.tail(5251439).to_csv(\n",
    "        DATADIR + 'country_rep/AuthorsField_1.tsv', sep='\\t', index=False,\n",
    "        columns=['FID','iso']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f3d476",
   "metadata": {},
   "source": [
    "## Top notch journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269522cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "topNotchJournals = pd.DataFrame([\n",
    "    ['PLoS_One','plos','multi'],\n",
    "    ['ijms','mdpi','Biology'],\n",
    "    ['Front_Microbiol','frontiers','Biology'],\n",
    "    ['Front_Immunol','frontiers','Biology'],\n",
    "    ['PNAS','pnas','multi'],\n",
    "    [6287639, 'ieee','Engineering']],\n",
    "    columns=['Journal','Publisher','FieldName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e96e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "topEditors = editors.merge(topNotchJournals, on=['Journal','Publisher'])\n",
    "\n",
    "topEditorCountryRep = (\n",
    "    pd.merge(\n",
    "        topEditors.groupby(['Publisher','Journal','iso']).AuthorId.count().reset_index().rename(columns={'AuthorId':'EdiCount'}),\n",
    "        topEditors.groupby(['Publisher','Journal']).AuthorId.count().reset_index().rename(columns={'AuthorId':'EdiTotal'}),\n",
    "        on=['Journal','Publisher']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce70d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "authorFieldCountryRep = (\n",
    "    pd.merge(\n",
    "        authors.merge(paperField, on='PaperId').groupby(['FieldName','iso']).AuthorId.count().reset_index().rename(columns={'AuthorId':'AutCount'}),\n",
    "        authors.merge(paperField, on='PaperId').groupby(['FieldName']).AuthorId.count().reset_index().rename(columns={'AuthorId':'AutTotal'}),\n",
    "        on=['FieldName']\n",
    "    )\n",
    ")\n",
    "\n",
    "authorAllCountryRep = (\n",
    "    authors\n",
    "    .groupby('iso').AuthorId.count().reset_index()\n",
    "    .rename(columns={'AuthorId':'AutCount'})\n",
    "    .assign(AutTotal=authors.shape[0])\n",
    ")\n",
    "\n",
    "authorCountryRep = (\n",
    "    pd.concat(\n",
    "        [authorFieldCountryRep,\n",
    "         authorAllCountryRep.assign(FieldName='multi')],\n",
    "        ignore_index=True, sort=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac4b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "topJournalISO = (\n",
    "    topNotchJournals.merge(topEditorCountryRep, on=['Publisher','Journal'])\n",
    "    .merge(authorCountryRep, on=['FieldName','iso'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topJournalISO.to_csv(DATADIR + 'country_rep/TopJournalCountryRep.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b87fb09",
   "metadata": {},
   "source": [
    "# Racial representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b759527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# processed in `fig_1_underrepresentation_of_countries.ipynb`\n",
    "\n",
    "authorsRace = (\n",
    "    authors\n",
    "    .drop('NormalizedName', axis=1)\n",
    "    \n",
    "    .query('iso == \"US\"')\n",
    "    \n",
    "    .merge(race, on='AuthorId')\n",
    "    \n",
    "    .query('Year >= 2001')\n",
    "    .query('Year <= 2020')\n",
    ")\n",
    "\n",
    "editorsRace = (\n",
    "    editors\n",
    "    .drop('NormalizedName', axis=1)\n",
    "    \n",
    "    .query('iso == \"US\"')\n",
    "    \n",
    "    .merge(race, on='AuthorId')\n",
    "    \n",
    "    .query('Year >= 2001')\n",
    "    .query('Year <= 2020')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ef4360",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(authorsRace.drop_duplicates().shape[0] == authorsRace.shape[0])\n",
    "assert(authorsRace.drop_duplicates().shape[0] == authorsRace.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "(\n",
    "    authorsRace\n",
    "    .to_csv(DATADIR + 'race_rep/Authors.tsv',sep='\\t',columns=['Publisher','Year','Race'],index=False)\n",
    ")\n",
    "\n",
    "(\n",
    "    editorsRace\n",
    "    .to_csv(DATADIR + 'race_rep/Editors.tsv',sep='\\t',columns=['Publisher','Year','Race'],index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d2a5ac",
   "metadata": {},
   "source": [
    "## Race representation by field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e91bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ediField = editorsRace.merge(paperField, on='PaperId').query('Year >= 2011').query('Year <= 2020')\n",
    "autField = authorsRace.merge(paperField, on='PaperId').query('Year >= 2011').query('Year <= 2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "(\n",
    "    ediField\n",
    "    .to_csv(DATADIR + 'race_rep/EditorsField.tsv',sep='\\t',columns=['FieldName','Year','Race'],index=False)\n",
    ")\n",
    "\n",
    "(\n",
    "    autField\n",
    "    .to_csv(DATADIR + 'race_rep/AuthorsField.tsv',sep='\\t',columns=['FieldName','Year','Race'],index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f825f",
   "metadata": {},
   "source": [
    "## Top notch journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topNotchJournals = pd.DataFrame([\n",
    "    ['PLoS_One','plos','multi', 'PLOS One'],\n",
    "    ['ijms','mdpi','Biology', 'Int. J. Mol. Sci.'],\n",
    "    ['Front_Microbiol','frontiers','Biology', 'Front. Microbiol.'],\n",
    "    ['Front_Immunol','frontiers','Biology', 'Front. Immunol.'],\n",
    "    ['PNAS','pnas','multi', 'PNAS'],\n",
    "    [6287639, 'ieee','Engineering', 'IEEE Access']],\n",
    "    columns=['Journal','Publisher','FieldName','JournalName'])\n",
    "topNotchJournals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a7346",
   "metadata": {},
   "outputs": [],
   "source": [
    "ediTop = (\n",
    "    editorsRace\n",
    "    .merge(topNotchJournals, on=['Journal', 'Publisher'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddd324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "autTop = (\n",
    "    pd.concat([\n",
    "        autField.drop(['Journal','Publisher'], axis=1)\n",
    "        .merge(topNotchJournals, on=['FieldName']),\n",
    "        autField.assign(JournalName='PLOS One').assign(Publisher='PLOS').assign(FieldName='multi'),\n",
    "        autField.assign(JournalName='PNAS').assign(Publisher='PNAS').assign(FieldName='multi'),\n",
    "    ], ignore_index=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc12c5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ediTop.to_csv(\n",
    "    DATADIR + 'race_rep/EditorsTopJournals.tsv',sep='\\t',index=False,\n",
    "    columns=['JournalName','Race','Year']\n",
    ")\n",
    "\n",
    "autTop.to_csv(\n",
    "    DATADIR + 'race_rep/AuthorsTopJournals.tsv',sep='\\t',index=False,\n",
    "    columns=['JournalName','Race','Year']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878653e7",
   "metadata": {},
   "source": [
    "# Acceptance delay by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6259f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = (\n",
    "    paperDelay.merge(papCountry, on='PaperId')\n",
    "    .merge(isoToC, on='iso')\n",
    "    .merge(continents, on='iso')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "paperByCountry = (\n",
    "    delay.groupby(['country','iso']).PaperId.nunique().reset_index()\n",
    "    .rename(columns={'PaperId':'Count'})\n",
    ")\n",
    "paperByCountry.to_csv(DATADIR + 'acpt_delay/CountryPaperCount.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0120000",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay.to_csv(\n",
    "    DATADIR + 'acpt_delay/PaperCountryDelay.tsv',sep='\\t',index=False,\n",
    "    columns=['Publisher','Year','JRelative','iso','country','region']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb2599d",
   "metadata": {},
   "source": [
    "## By Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7350f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldDelay = (\n",
    "    delay\n",
    "    .merge(colorsDf, on='region')\n",
    "    .merge(paperField, on='PaperId')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db9ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldDelay.to_csv(\n",
    "    DATADIR + 'acpt_delay/PaperFieldDelay.tsv',sep='\\t',index=False,\n",
    "    columns=['Year','FieldName','Color','JRelative']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e142c32",
   "metadata": {},
   "source": [
    "## Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d666bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sameCountry = pd.read_csv(PROJDIR + 'PaperEditorAuthorSameCountry.csv',sep='\\t')\n",
    "sameCountry.shape, sameCountry.PaperId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "toPlotDelayAll = pd.read_csv(DATADIR + 'acpt_delay/Countries.tsv', sep='\\t')\n",
    "interactionCountries = toPlotDelayAll[['iso']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa61bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction = (\n",
    "    interactionCountries.merge(delay, on='iso')\n",
    "    .merge(sameCountry, on='PaperId')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction.to_csv(\n",
    "    DATADIR + 'acpt_delay/CountryInteraction.tsv',sep='\\t',index=False,\n",
    "    columns=['iso','country','SameCountry','JRelative']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccc18d1",
   "metadata": {},
   "source": [
    "# Acceptance delay by race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c25474",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "raceDelay = (\n",
    "    USpapers.merge(paperDelay, on='PaperId')\n",
    "    \n",
    "    .merge(paperRace, on='PaperId')\n",
    "    \n",
    "    .query('Year >= 2000')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f84e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raceDelay.to_csv(DATADIR + 'acpt_delay/PaperRaceDelay.tsv',sep='\\t',index=False,columns=['Year','Race','JRelative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d9bb45",
   "metadata": {},
   "source": [
    "## Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "interaction = (\n",
    "    paperDelay[['PaperId','JRelative']]\n",
    "    .merge(USpapers, on='PaperId')\n",
    "    \n",
    "    .merge(\n",
    "        editorRace\n",
    "        .query('Race != \"unknown\"')\n",
    "        .rename(columns={'Race':'EditorRace'})\n",
    "        [['PaperId','EditorRace']], on='PaperId'\n",
    "    )\n",
    "    .merge(\n",
    "        paperRace\n",
    "        .query('Race != \"unknown\"')\n",
    "        .rename(columns={'Race':'PaperRace'})\n",
    "        [['PaperId','PaperRace']], on='PaperId'\n",
    "    )\n",
    "    .assign(PaperIsWhite=lambda df: df.PaperRace.apply(lambda x: x=='White'))\n",
    "    .assign(EditorIsWhite=lambda df: df.EditorRace.apply(lambda x: x=='White'))\n",
    "    \n",
    "    .assign(PaperIsBlack=lambda df: df.PaperRace.apply(lambda x: x=='Black'))\n",
    "    .assign(EditorIsBlack=lambda df: df.EditorRace.apply(lambda x: x=='Black'))\n",
    "    \n",
    "    .assign(SameRace=lambda df: df.apply(lambda row: row['PaperRace'] == row['EditorRace'], axis=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969bc181",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction.to_csv(\n",
    "    DATADIR + 'acpt_delay/RaceInteraction.tsv',sep='\\t',index=False,\n",
    "    columns=['PaperIsWhite','EditorIsWhite','JRelative']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc6282e",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1916beb7",
   "metadata": {},
   "source": [
    "### Compute paper attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87600d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paperAuthor = papAuNoAff.merge(paperDelay[['PaperId']].drop_duplicates(), on='PaperId')\n",
    "paperAuthorAff = papAu.merge(paperDelay[['PaperId']].drop_duplicates(), on='PaperId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e31ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paperAuthorCount = (\n",
    "    paperAuthor.groupby('PaperId').AuthorId.nunique()\n",
    "    .reset_index().rename(columns={'AuthorId':'Total'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b7540",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paperRaceCount = (\n",
    "    paperAuthor.merge(race[race.Race.isin(['White', 'Hispanic', 'API', 'Black'])], on='AuthorId')\n",
    "    \n",
    "    .groupby(['PaperId','Race']).AuthorId.nunique().reset_index()\n",
    "    .rename(columns={'AuthorId':'RaceCount'})\n",
    "    .merge(paperAuthorCount, on='PaperId')\n",
    "    .assign(RacePercent = lambda df: df.apply(lambda row: row.RaceCount/row.Total, axis=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc533c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paperCountryCount = (\n",
    "    paperAuthorAff.merge(affiliations, on='AffiliationId')\n",
    "    \n",
    "    .groupby(['PaperId','iso']).AuthorId.nunique().reset_index()\n",
    "    .rename(columns={'AuthorId':'CountryCount'})\n",
    "    \n",
    "    .merge(paperAuthorCount, on='PaperId')\n",
    "    .assign(CountryPercent = lambda df: df.apply(lambda row: row.CountryCount/row.Total, axis=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3358023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paperCountryPivot = (\n",
    "    paperCountryCount.pivot(index='PaperId', columns='iso', values='CountryCount').fillna(0).reset_index()\n",
    ")\n",
    "\n",
    "paperRacePivot = (\n",
    "    paperRaceCount.pivot(index='PaperId', columns='Race', values='RaceCount').fillna(0).reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd4c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paperAffRank = (\n",
    "    paperAuthorAff.merge(rank, on='AffiliationId', how='left').fillna({'Rank':1001})\n",
    "    .groupby(['PaperId']).Rank.min().reset_index()\n",
    "    .assign(Rank = lambda df: df.Rank.astype(int))\n",
    ") # 1000990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c958d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paperAge = (\n",
    "    paperAuthor.merge(paper_year, on='PaperId')\n",
    "    .merge(authorCareer, on='AuthorId')\n",
    "    .assign(Age = lambda df: df.Year - df.Yfp)\n",
    "    .groupby('PaperId').Age.max().reset_index()\n",
    ") # 1000989"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc80e522",
   "metadata": {},
   "source": [
    "#### Editor country and race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bf35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "editorAff = (\n",
    "    pd.read_csv(PROJDIR + 'EditorAffiliationYear.csv', sep='\\t', usecols=['AuthorId','Year','iso'])\n",
    "    .drop_duplicates()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecada3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paperEditorCountry = (\n",
    "    paperEditor.rename(columns={'EditorId':'AuthorId'})\n",
    "    .merge(paper_year, on='PaperId')\n",
    "    .merge(editorAff, on=['AuthorId','Year'])\n",
    "    .rename(columns={'AuthorId':'EditorId', 'iso':'EditorIso'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446838dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sameCountry = (\n",
    "    paperEditorCountry.merge(paperCountryCount, on='PaperId')\n",
    "    \n",
    "    .assign(Same = lambda df: df.iso == df.EditorIso)\n",
    "    .groupby('PaperId').Same.any().reset_index()\n",
    "    .rename(columns={'Same':'SameCountry'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc9a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paperEditorRace = (\n",
    "    paperEditor.rename(columns={'EditorId':'AuthorId'}).merge(race, on='AuthorId')\n",
    "    .pipe(printShape)\n",
    "    \n",
    "    .rename(columns={'AuthorId':'EditorId', 'Race':'EditorRace'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a6042",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sameRace = (\n",
    "    paperEditorRace.merge(paperRaceCount, on='PaperId')\n",
    "    \n",
    "    .assign(Same = lambda df: df.Race == df.EditorRace)\n",
    "    .groupby('PaperId').Same.any().reset_index()\n",
    "    .rename(columns={'Same':'SameRace'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964cc08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "editorRaceCountry = (\n",
    "    paperDelay[['PaperId']].drop_duplicates()\n",
    "    .merge(sameRace, on='PaperId', how='left')\n",
    "    .merge(sameCountry, on='PaperId', how='left')\n",
    "    .fillna({'SameRace':False, 'SameCountry':False})\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cce208f",
   "metadata": {},
   "source": [
    "#### Paper field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df7ca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldname = (\n",
    "    pd.read_csv(MAGDIR + \"advanced/FieldsOfStudy.txt\", sep=\"\\t\", \n",
    "                names = [\"FieldOfStudyId\", \"Rank\", \"NormalizedName\", \"DisplayName\", \n",
    "                         \"MainType\",\"Level\",\"PaperCount\",\"PaperFamilyCount\", \"CitationCount\",\"CreatedDate\"],\n",
    "                usecols=['FieldOfStudyId', 'DisplayName']\n",
    "               )\n",
    "    .rename(columns={'FieldOfStudyId':'Field', 'DisplayName':'FieldName'})\n",
    "    .dropna()\n",
    "    .assign(FieldName = lambda df: df.FieldName.apply(lambda x: '_'.join(x.split())))\n",
    ")\n",
    "\n",
    "paperField = (\n",
    "    pd.read_csv(PROJDIR + 'PaperField.csv', sep='\\t', dtype={'PaperId':int}, usecols=['PaperId','Field'])\n",
    "    .merge(fieldname, on='Field')\n",
    "    .drop('Field', axis=1)\n",
    ")\n",
    "\n",
    "\n",
    "oneField = paperField.drop_duplicates(subset='PaperId', keep=False)\n",
    "\n",
    "paperField = (\n",
    "    pd.concat([oneField,\n",
    "               (\n",
    "                   paperField[~paperField.PaperId.isin(oneField.PaperId)]\n",
    "                   .assign(FieldName='multi')\n",
    "                   .drop_duplicates()\n",
    "               )], ignore_index=True, sort=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6669b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "paperFieldPivot = (\n",
    "    paperField.assign(Value=1).pivot(index='PaperId',columns='FieldName',values='Value')\n",
    "    .fillna(0).reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961baea3",
   "metadata": {},
   "source": [
    "### Gather paper attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad804035",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paperDf = (\n",
    "    paperDelay[['PaperId','JRelative']].drop_duplicates()\n",
    "    .merge(paper_year, on='PaperId')\n",
    "    .merge(paperAuthorCount, on='PaperId')\n",
    "    .merge(paperRacePivot, on='PaperId')\n",
    "    .merge(paperCountryPivot, on='PaperId')\n",
    "    .merge(paperAffRank, on='PaperId')\n",
    "    .merge(paperAge, on='PaperId')\n",
    "    .merge(editorRaceCountry, on='PaperId')\n",
    "    .merge(paperFieldPivot, on='PaperId')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b43a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1467c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for ind, df in tqdm(enumerate(np.array_split(paperDf, 10))):\n",
    "    df.drop(['PaperId'],axis=1).to_csv(DATADIR + f'acpt_delay/regression_data/{ind}.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5811a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paperDf.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc45e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_control = ' + '.join([x for x in paperCountryCount.iso.unique() if x != 'US']) # relative to US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d71a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATADIR + 'CountryControl.txt', 'w+') as f:\n",
    "    f.write(country_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0a7b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
